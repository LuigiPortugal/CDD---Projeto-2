{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassificator:\n",
    "    \n",
    "    # Initializing the classificator, which can be customized\n",
    "    def __init__(self, n_gram=1, stem=True, stop_words=True, alpha=1, class_prob=None):\n",
    "        # Variable that defines the size of the gram to be used\n",
    "        self.n_gram = n_gram\n",
    "        # Boolean that defines if the words will be stemmized or not\n",
    "        self.stem = stem\n",
    "        # Boolean that defines if stop_words will be removed\n",
    "        self.stop_words = stop_words\n",
    "        # Variable that defines which alpha will be used for the Smoothing of probabilities.\n",
    "        self.alpha = alpha\n",
    "        \"\"\"\n",
    "        class-prob defines how the probability of a specific classification (P(class)) will be calculated\n",
    "        if None -> P(category) = (number of appearances of the category)/(total)\n",
    "        if \"equal\" -> P(category) = 1/(number of categories)\n",
    "        \"\"\"\n",
    "        self.class_prob = class_prob\n",
    "        # Stemmer that is used if words are to be stemmed\n",
    "        self.stemmer = nltk.stem.RSLPStemmer()\n",
    "        # List with the stop-words\n",
    "        self.stop_words_list = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    # This function is utilized to clean the sentence\n",
    "    def _clean_sentence(self, sentence):\n",
    "        \n",
    "        # Error occurred while testing. String created to avoid errors\n",
    "        string = str(sentence)\n",
    "    \n",
    "        # Cleaning unwanted characters on the sentence\n",
    "        string = string.replace(\":\", \" \")\n",
    "        string = string.replace(\";\", \" \")\n",
    "        string = string.replace(\",\", \" \")\n",
    "        string = string.replace(\"?\", \" \")\n",
    "        string = string.replace(\"(\", \" \")\n",
    "        string = string.replace(\")\", \" \")\n",
    "        string = string.replace(\"\\n\", \" \")\n",
    "        string = string.replace(\"'\", \" \")\n",
    "        string = string.replace(\".\", \" \")\n",
    "        string = string.replace('\"', \" \")\n",
    "        string = string.replace(\"!\", \" \")\n",
    "        string = string.replace(\"@\", \" \")\n",
    "        #l Lowercasing all letters, avoids comparisson.\n",
    "        string = string.lower()\n",
    "\n",
    "        # Converting the sentence into a list of words\n",
    "        string_list = []\n",
    "        \n",
    "        for word in string.split():\n",
    "            # Checks if the classifier should remove stop-words\n",
    "            if self.stop_words:\n",
    "                # Checks if the word is a stop-word\n",
    "                if word not in self.stop_words_list:\n",
    "                    # Checks if the classifier should stemmize the words\n",
    "                    if self.stem:\n",
    "                        string_list.append(self.stemmer.stem(word))\n",
    "                    else:\n",
    "                        string_list.append(word)\n",
    "            else:\n",
    "                # Checks if the classifier should stemmize the words\n",
    "                if self.stem:\n",
    "                    string_list.append(self.stemmer.stem(word))\n",
    "                else:\n",
    "                    string_list.append(word)\n",
    "                    \n",
    "        \n",
    "        # Returns the n-gram list of the words\n",
    "        return self._create_gram(string_list)\n",
    "\n",
    "    # Function that creates the n-gram list of the words\n",
    "    def _create_gram(self, words_list):\n",
    "        bigram = []\n",
    "        # The self.n_gram variable defines how many words will be linked together\n",
    "        for n in range(len(words_list) + 1 - self.n_gram):\n",
    "            bigram.append(\" \".join(words_list[n:n+self.n_gram]))\n",
    "        return bigram\n",
    "\n",
    "    # Function that create a dictionary with the words that appear in a sentence, and its frequencies\n",
    "    def _create_dict(self, sentences_series):\n",
    "\n",
    "        \n",
    "        count = {}\n",
    "\n",
    "        for sentence in sentences_series:\n",
    "            # Cleans sentence prior to counting the frequencies\n",
    "            words_list = self._clean_sentence(sentence)\n",
    "            for word in words_list:\n",
    "                if word in count:\n",
    "                    count[word] += 1\n",
    "                else:\n",
    "                    count[word] = 1\n",
    "                        \n",
    "        return count\n",
    "    \n",
    "    # Function that calculates the d, variable used on the Smoothing of the Probability\n",
    "    def _get_d(self, df, x_label):\n",
    "        \n",
    "        words = []\n",
    "        for sentence in df[x_label]:\n",
    "            for word in self._clean_sentence(sentence):\n",
    "                if word not in words:\n",
    "                    words.append(word)\n",
    "                    \n",
    "        # It returns the total words of the dataset\n",
    "        return len(words)\n",
    "    \n",
    "    # Function that calculates the probability of a specific category\n",
    "    def _calc_prob(self, sentence, e):\n",
    "        \n",
    "        \"\"\"\n",
    "        We are using log for the probabilities to get a higher accuracy on the calculation\n",
    "        If you don't use log:\n",
    "            P(sentence|category) = P(word1|category)*P(word2|category)*...*P(lastword|category)\n",
    "        Applying log:\n",
    "            log(P(sentence|category)) = log(P(word1|category)) + log(P(word2|category)) + ... + log(P(lastword|category))\n",
    "        \"\"\"\n",
    "        \n",
    "        # Starts the probability with the probability of the specific category\n",
    "        prob = log(self.classes_dicts[e][\"class_prob\"])\n",
    "    \n",
    "        # Alpha factor for the LaPlace smoothing\n",
    "        total = self.classes_dicts[e][\"n_words\"] + self.alpha*self.d\n",
    "        \n",
    "        # Calculates the probability for each word (or n-gram) in the cleaned sentence\n",
    "        for word in self._clean_sentence(sentence):\n",
    "            if word in self.classes_dicts[e][\"words\"]:\n",
    "                count = self.classes_dicts[e][\"words\"][word] + self.alpha\n",
    "            else:\n",
    "                count = self.alpha\n",
    "            prob += log(count/total)\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    # Function that classifies the sentence\n",
    "    def _classify(self, sentence):\n",
    "        \n",
    "        # Variable that stores the highest probability and which category it represents.\n",
    "        highest = [None, None]\n",
    "        \n",
    "        # Calculates the probability for each category\n",
    "        for e in self.classes:\n",
    "            classes_probs = self._calc_prob(sentence, e)\n",
    "            if highest[0] is not None:\n",
    "                # Checks if the probability for that category is higher than the highest probability \n",
    "                if classes_probs > highest[1]:\n",
    "                    highest[0] = e\n",
    "                    highest[1] = classes_probs\n",
    "            # It runs on the first iteration of the for loop. To initialize the 'highest' list\n",
    "            else:\n",
    "                highest[0] = e\n",
    "                highest[1] = classes_probs\n",
    "                \n",
    "        # Returns the classification for that sentence\n",
    "        return highest[0]            \n",
    "    \n",
    "    # This function is used to \"teach\" the classifier based on the training data\n",
    "    def fit(self, df, x_label, y_label):\n",
    "        \n",
    "        self.df = df\n",
    "        self.x_label = x_label\n",
    "        self.y_label = y_label\n",
    "        \n",
    "        # Stores the possible categories to classify\n",
    "        self.classes = []\n",
    "        for e in df[y_label]:\n",
    "            if e not in self.classes:\n",
    "                self.classes.append(e)\n",
    "                \n",
    "        \"\"\"\n",
    "        Creates a dictionary with informations of each category\n",
    "        keys: values\n",
    "            \"words\": dictionary with the informations of words (or n-grams) in the category\n",
    "            \"n-words\": number of words (or n-grams) in the category\n",
    "            \"class-prob\": probability of that specific category\n",
    "        \"\"\"\n",
    "        self.classes_dicts = {}\n",
    "        \n",
    "        # Completes classes_dicts\n",
    "        for e in self.classes:\n",
    "            self.classes_dicts[e] = {}\n",
    "            self.classes_dicts[e][\"words\"] = self._create_dict(df[df[y_label] == e][x_label])\n",
    "            self.classes_dicts[e][\"n_words\"] = len(self.classes_dicts[e][\"words\"])\n",
    "            if self.class_prob == None:\n",
    "                self.classes_dicts[e][\"class_prob\"] = df[df[y_label] == e][x_label].count()/df[x_label].count()\n",
    "            elif self.class_prob == \"equal\":\n",
    "                self.classes_dicts[e][\"class_prob\"] = 1/len(self.classes)\n",
    "            \n",
    "        # Creates the d (for the smoothing)\n",
    "        self.d = self._get_d(df, x_label)\n",
    "            \n",
    "    # Function used to predict the classification of a specific series\n",
    "    def predict(self, sentence_series):\n",
    "        \n",
    "        # List with the predictions\n",
    "        predictions = []\n",
    "        \n",
    "        # Classify each sentence\n",
    "        for sentence in sentence_series:\n",
    "            predictions.append(self._classify(sentence))\n",
    "            \n",
    "        # Returns the classifications as a series -> easier to manipulate later with the df\n",
    "        return pd.Series(predictions)\n",
    "    \n",
    "    # Evaluates the classifier performance\n",
    "    def evaluate(self, y_test, y_pred):\n",
    "        \n",
    "        # Count for the correct predictions\n",
    "        count = 0\n",
    "        \n",
    "        # Compares the predictions with the real classifications\n",
    "        for e in range(len(y_test)):\n",
    "            if y_test.loc[e] == y_pred.loc[e]:\n",
    "                count += 1\n",
    "                \n",
    "        # Returns a tuple with the Accuracy and the number of correct predictions\n",
    "        performance = count/(y_test.count())\n",
    "        return (performance, count)\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a confusion_matrix for the classifier predictions\n",
    "    Problem to be resolved -> does not work with categories that are not numbered and started on 0\n",
    "    \"\"\"\n",
    "    def confusion_matrix(self, y_test, y_pred):\n",
    "        \n",
    "        n = [[0] * len(self.classes)] * len(self.classes)\n",
    "        cm = np.array(n)\n",
    "        \n",
    "        for e in range(len(y_test)):\n",
    "            cls = y_test.loc[e]\n",
    "            pred = y_pred.loc[e]\n",
    "            cm[cls][pred] += 1\n",
    "            \n",
    "        return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the classifier\n",
    "classifier = NaiveBayesClassificator(n_gram=2, alpha=1, class_prob=None, stop_words=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Por que não usar o classificador para obter mais amostras de treinamento?</h4>\n",
    "\n",
    "<p>Classificando manualmente as amostras de treinamento, criamos um referencial para nosso classificador, “ensinando-o” o que considerar irrelevante, bom ou ruim. Em outras palavras criamos um data frame em que o classificador possa se embasar ao classificar novas amostras. </p>\n",
    "\n",
    "<p>Uma vez que as amostras de treinamento têm essa utilidade, seria imprudente utilizar o próprio classificador para gerar mais amostras para ele próprio treinar. O usuário não teria como saber se a classificação feita pelo programa é correta, pois o programa por si só não é capaz de distinguir as classes positivas, negativas e irrelevantes  sem embasamento em amostras classificadas pelo o usuário</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Diferentes cenários onde pode ser ultilizado Naïve Bayes</h4>\n",
    "\n",
    "* Desenvolvimento de um programa para detecção de falhas de um manipulador robótico:\n",
    "\n",
    "   <p> Alguns manipuladores robóticos podem apresentar problemas de calibração e em muitos casos são desenvolvidos programas para identificar essas falhas. O classificador de Naive Bayes pode ser útil para distinguir a precisão desse programa e se realmente identificou um erro \"relevante\". Uma demonstração formal dessa ultilização pode ser encontrada no link abaixo </p>\n",
    "\n",
    "    <p>http://abcm.org.br/upload/files/PII_I_03%281%29.pdf</p>\n",
    "\n",
    "    <p>É possível observar nesse ensaio que foi classficado cada tipo de erro que o programa detecta. Assim foram feitos testes para cada classe de erros e ,a partir da observação dos testes, calcular a precisão do programa. Com isso, é possível usar a lógica do classificador de Naive Bayes para ter a probabilidade da  identificação de erros que o programa detecta (neste caso, o programa tem 83% de acerto na identificação de erros).</p> \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
