{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassificator:\n",
    "    \n",
    "    # Initializing the classificator, which can be customized\n",
    "    def __init__(self, n_gram=1, stem=True, stop_words=True, alpha=1, class_prob=None):\n",
    "        # Variable that defines the size of the gram to be used\n",
    "        self.n_gram = n_gram\n",
    "        # Boolean that defines if the words will be stemmized or not\n",
    "        self.stem = stem\n",
    "        # Boolean that defines if stop_words will be removed\n",
    "        self.stop_words = stop_words\n",
    "        # Variable that defines which alpha will be used for the Smoothing of probabilities.\n",
    "        self.alpha = alpha\n",
    "        \"\"\"\n",
    "        class-prob defines how the probability of a specific classification (P(class)) will be calculated\n",
    "        if None -> P(category) = (number of appearances of the category)/(total)\n",
    "        if \"equal\" -> P(category) = 1/(number of categories)\n",
    "        \"\"\"\n",
    "        self.class_prob = class_prob\n",
    "        # Stemmer that is used if words are to be stemmed\n",
    "        self.stemmer = nltk.stem.RSLPStemmer()\n",
    "        # List with the stop-words\n",
    "        self.stop_words_list = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    # This function is utilized to clean the sentence\n",
    "    def _clean_sentence(self, sentence):\n",
    "        \n",
    "        # Error occurred while testing. String created to avoid errors\n",
    "        string = str(sentence)\n",
    "    \n",
    "        # Cleaning unwanted characters on the sentence\n",
    "        string = string.replace(\":\", \" \")\n",
    "        string = string.replace(\";\", \" \")\n",
    "        string = string.replace(\",\", \" \")\n",
    "        string = string.replace(\"?\", \" \")\n",
    "        string = string.replace(\"(\", \" \")\n",
    "        string = string.replace(\")\", \" \")\n",
    "        string = string.replace(\"\\n\", \" \")\n",
    "        string = string.replace(\"'\", \" \")\n",
    "        string = string.replace(\".\", \" \")\n",
    "        string = string.replace('\"', \" \")\n",
    "        string = string.replace(\"!\", \" \")\n",
    "        string = string.replace(\"@\", \" \")\n",
    "        #l Lowercasing all letters, avoids comparisson.\n",
    "        string = string.lower()\n",
    "\n",
    "        # Converting the sentence into a list of words\n",
    "        string_list = []\n",
    "        \n",
    "        for word in string.split():\n",
    "            # Checks if the classifier should remove stop-words\n",
    "            if self.stop_words:\n",
    "                # Checks if the word is a stop-word\n",
    "                if word not in self.stop_words_list:\n",
    "                    # Checks if the classifier should stemmize the words\n",
    "                    if self.stem:\n",
    "                        string_list.append(self.stemmer.stem(word))\n",
    "                    else:\n",
    "                        string_list.append(word)\n",
    "            else:\n",
    "                # Checks if the classifier should stemmize the words\n",
    "                if self.stem:\n",
    "                    string_list.append(self.stemmer.stem(word))\n",
    "                else:\n",
    "                    string_list.append(word)\n",
    "                    \n",
    "        \n",
    "        # Returns the n-gram list of the words\n",
    "        return self._create_gram(string_list)\n",
    "\n",
    "    # Function that creates the n-gram list of the words\n",
    "    def _create_gram(self, words_list):\n",
    "        bigram = []\n",
    "        # The self.n_gram variable defines how many words will be linked together\n",
    "        for n in range(len(words_list) + 1 - self.n_gram):\n",
    "            bigram.append(\" \".join(words_list[n:n+self.n_gram]))\n",
    "        return bigram\n",
    "\n",
    "    # Function that create a dictionary with the words that appear in a sentence, and its frequencies\n",
    "    def _create_dict(self, sentences_series):\n",
    "\n",
    "        \n",
    "        count = {}\n",
    "\n",
    "        for sentence in sentences_series:\n",
    "            # Cleans sentence prior to counting the frequencies\n",
    "            words_list = self._clean_sentence(sentence)\n",
    "            for word in words_list:\n",
    "                if word in count:\n",
    "                    count[word] += 1\n",
    "                else:\n",
    "                    count[word] = 1\n",
    "                        \n",
    "        return count\n",
    "    \n",
    "    # Function that calculates the d, variable used on the Smoothing of the Probability\n",
    "    def _get_d(self, df, x_label):\n",
    "        \n",
    "        words = []\n",
    "        for sentence in df[x_label]:\n",
    "            for word in self._clean_sentence(sentence):\n",
    "                if word not in words:\n",
    "                    words.append(word)\n",
    "                    \n",
    "        # It returns the total words of the dataset\n",
    "        return len(words)\n",
    "    \n",
    "    # Function that calculates the probability of a specific category\n",
    "    def _calc_prob(self, sentence, e):\n",
    "        \n",
    "        \"\"\"\n",
    "        We are using log for the probabilities to get a higher accuracy on the calculation\n",
    "        If you don't use log:\n",
    "            P(sentence|category) = P(word1|category)*P(word2|category)*...*P(lastword|category)\n",
    "        Applying log:\n",
    "            log(P(sentence|category)) = log(P(word1|category)) + log(P(word2|category)) + ... + log(P(lastword|category))\n",
    "        \"\"\"\n",
    "        \n",
    "        # Starts the probability with the probability of the specific category\n",
    "        prob = log(self.classes_dicts[e][\"class_prob\"])\n",
    "    \n",
    "        # Alpha factor for the LaPlace smoothing\n",
    "        total = self.classes_dicts[e][\"n_words\"] + self.alpha*self.d\n",
    "        \n",
    "        # Calculates the probability for each word (or n-gram) in the cleaned sentence\n",
    "        for word in self._clean_sentence(sentence):\n",
    "            if word in self.classes_dicts[e][\"words\"]:\n",
    "                count = self.classes_dicts[e][\"words\"][word] + self.alpha\n",
    "            else:\n",
    "                count = self.alpha\n",
    "            prob += log(count/total)\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    # Function that classifies the sentence\n",
    "    def _classify(self, sentence):\n",
    "        \n",
    "        # Variable that stores the highest probability and which category it represents.\n",
    "        highest = [None, None]\n",
    "        \n",
    "        # Calculates the probability for each category\n",
    "        for e in self.classes:\n",
    "            classes_probs = self._calc_prob(sentence, e)\n",
    "            if highest[0] is not None:\n",
    "                # Checks if the probability for that category is higher than the highest probability \n",
    "                if classes_probs > highest[1]:\n",
    "                    highest[0] = e\n",
    "                    highest[1] = classes_probs\n",
    "            # It runs on the first iteration of the for loop. To initialize the 'highest' list\n",
    "            else:\n",
    "                highest[0] = e\n",
    "                highest[1] = classes_probs\n",
    "                \n",
    "        # Returns the classification for that sentence\n",
    "        return highest[0]            \n",
    "    \n",
    "    # This function is used to \"teach\" the classifier based on the training data\n",
    "    def fit(self, df, x_label, y_label):\n",
    "        \n",
    "        self.df = df\n",
    "        self.x_label = x_label\n",
    "        self.y_label = y_label\n",
    "        \n",
    "        # Stores the possible categories to classify\n",
    "        self.classes = []\n",
    "        for e in df[y_label]:\n",
    "            if e not in self.classes:\n",
    "                self.classes.append(e)\n",
    "                \n",
    "        \"\"\"\n",
    "        Creates a dictionary with informations of each category\n",
    "        keys: values\n",
    "            \"words\": dictionary with the informations of words (or n-grams) in the category\n",
    "            \"n-words\": number of words (or n-grams) in the category\n",
    "            \"class-prob\": probability of that specific category\n",
    "        \"\"\"\n",
    "        self.classes_dicts = {}\n",
    "        \n",
    "        # Completes classes_dicts\n",
    "        for e in self.classes:\n",
    "            self.classes_dicts[e] = {}\n",
    "            self.classes_dicts[e][\"words\"] = self._create_dict(df[df[y_label] == e][x_label])\n",
    "            self.classes_dicts[e][\"n_words\"] = len(self.classes_dicts[e][\"words\"])\n",
    "            if self.class_prob == None:\n",
    "                self.classes_dicts[e][\"class_prob\"] = df[df[y_label] == e][x_label].count()/df[x_label].count()\n",
    "            elif self.class_prob == \"equal\":\n",
    "                self.classes_dicts[e][\"class_prob\"] = 1/len(self.classes)\n",
    "            \n",
    "        # Creates the d (for the smoothing)\n",
    "        self.d = self._get_d(df, x_label)\n",
    "            \n",
    "    # Function used to predict the classification of a specific series\n",
    "    def predict(self, sentence_series):\n",
    "        \n",
    "        # List with the predictions\n",
    "        predictions = []\n",
    "        \n",
    "        # Classify each sentence\n",
    "        for sentence in sentence_series:\n",
    "            predictions.append(self._classify(sentence))\n",
    "            \n",
    "        # Returns the classifications as a series -> easier to manipulate later with the df\n",
    "        return pd.Series(predictions)\n",
    "    \n",
    "    # Evaluates the classifier performance\n",
    "    def evaluate(self, y_test, y_pred):\n",
    "        \n",
    "        # Count for the correct predictions\n",
    "        count = 0\n",
    "        \n",
    "        # Compares the predictions with the real classifications\n",
    "        for e in range(len(y_test)):\n",
    "            if y_test.loc[e] == y_pred.loc[e]:\n",
    "                count += 1\n",
    "                \n",
    "        # Returns a tuple with the Accuracy and the number of correct predictions\n",
    "        performance = count/(y_test.count())\n",
    "        return (performance, count)\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a confusion_matrix for the classifier predictions\n",
    "    Problem to be resolved -> does not work with categories that are not numbered and started on 0\n",
    "    \"\"\"\n",
    "    def confusion_matrix(self, y_test, y_pred):\n",
    "        \n",
    "        n = [[0] * len(self.classes)] * len(self.classes)\n",
    "        cm = np.array(n)\n",
    "        \n",
    "        for e in range(len(y_test)):\n",
    "            cls = y_test.loc[e]\n",
    "            pred = y_pred.loc[e]\n",
    "            cm[cls][pred] += 1\n",
    "            \n",
    "        return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testando nosso classificador para 3 Categorias possíveis:</h3>\n",
    "\n",
    "<ul> Categorias Possíveis\n",
    "    <li> 0 - Tweet Negativo </li>\n",
    "    <li> 1 - Tweet Irrelevante </li>\n",
    "    <li> 2 - Tweet Positivo </li>\n",
    "</ul>\n",
    "\n",
    "<p>Para a classificação em 3 categorias nós testamos algumas classificadores com categorias diferentes, a fim de entender qual seria a melhor opção.</p>\n",
    "<p>Durante os testes, percebemos que não utilizando a <i>stemização</i> das palavras e não retirando as stop-words a classificação era mais eficaz.</p>\n",
    "<p>Como não possuímos uma explicação palpável para tal, resolvemos demonstrar três classificadores que alteram suas caracteristicas quanto as duas limpagens citadas acima.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the classifier\n",
    "classifier1 = NaiveBayesClassificator(n_gram=2, alpha=1, class_prob=None)\n",
    "classifier2 = NaiveBayesClassificator(n_gram=2, alpha=1, class_prob=None, stop_words=False)\n",
    "classifier3 = NaiveBayesClassificator(n_gram=2, alpha=1, class_prob=None, stop_words=False, stem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Dataset\n",
    "df_train = pd.read_excel(\"smartfit_naivebayes_3categorias.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the DataSet on the classifiers\n",
    "classifier1.fit(df_train, 'Treinamento', 'Classificação')\n",
    "classifier2.fit(df_train, 'Treinamento', 'Classificação')\n",
    "classifier3.fit(df_train, 'Treinamento', 'Classificação')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test set\n",
    "df_test = pd.read_excel(\"smartfit_naivebayes_3categorias.xlsx\", sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the categories of the test set with each classifier\n",
    "pred_1 = classifier1.predict(df_test['Teste'])\n",
    "pred_2 = classifier2.predict(df_test['Teste'])\n",
    "pred_3 = classifier3.predict(df_test['Teste'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the accuracy of each classifier\n",
    "acc_1 = classifier1.evaluate(df_test['Classificação'], pred_1)\n",
    "acc_2 = classifier2.evaluate(df_test['Classificação'], pred_2)\n",
    "acc_3 = classifier3.evaluate(df_test['Classificação'], pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador 1: 131 acertos -> 65.50%\n",
      "Classificador 2: 143 acertos -> 71.50%\n",
      "Classificador 3: 145 acertos -> 72.50%\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the results\n",
    "print(\"Classificador 1: {0} acertos -> {1:.2f}%\".format(acc_1[1], 100*acc_1[0]))\n",
    "print(\"Classificador 2: {0} acertos -> {1:.2f}%\".format(acc_2[1], 100*acc_2[0]))\n",
    "print(\"Classificador 3: {0} acertos -> {1:.2f}%\".format(acc_3[1], 100*acc_3[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Como podemos perceber, o classificador que não <i>stemiza</i> as palavras e não remove as stop-words (classificador 3) possui uma acuracia melhor.</p>\n",
    "<p>Agora criaremos uma Matriz de Confusão para o classificador 3, buscando entender melhor como funcionam suas classificações.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  5, 20],\n",
       "       [ 2, 93,  9],\n",
       "       [ 7, 12, 37]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier3.confusion_matrix(df_test[\"Classificação\"], pred_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Vamos interpretar esses valores em uma tabela mais fácil de ser entendida</p>\n",
    "\n",
    "\n",
    "| --------- | Negativo      | Irrelevante    | Positivo   |\n",
    "| --------- | ------------- |----------------| ---------- |\n",
    "|**Negativo** | 15            | 5              | 20         |\n",
    "|**Irrelevante**| 2             |  93            | 9          |\n",
    "|**Positivo**| 7             | 12             | 37         |\n",
    "\n",
    "\n",
    "<p>Nessa tabela, as colunas correspondem às predições de nosso classificador, e as linhas a real categoria de uma determinada frase. A partir dela podemos obter as probabilidades de o classificador acertar uma frase dada sua categoria. Fazendo as contas teremos:</p>\n",
    "\n",
    "$\n",
    "\\begin{equation}\\mathcal{P} (\\text{acertar | frase negativa}) = \\frac{15}{40} = 0.375\\end{equation}\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase irrelevante}) = \\frac{93}{104} = 0.894\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase positiva}) = \\frac{37}{56} = 0.661\n",
    "$\n",
    "\n",
    "<p>Considerando que no DataSet nós temos a seguinte distribuição para a quantidade de classificações no arquivo de teste:\n",
    "    <ul>\n",
    "        <li>Negativas: 20%</li>\n",
    "        <li>Irrelevantes: 52%</li>\n",
    "        <li>Positivo: 28%</li>\n",
    "    </ul>\n",
    "e dadas as probabilidades de acerto (maiores que a distribuição das categorias), o grupo considera que nosso classificador teve um bom desempenho para essa classificação!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testando nosso classificador para 5 Categorias possíveis:</h3>\n",
    "\n",
    "<ul> Categorias Possíveis\n",
    "    <li> 0 - Tweet Muito Irrelevante </li>\n",
    "    <li> 1 - Tweet Irrelevante </li>\n",
    "    <li> 2 - Tweet Neutro </li>\n",
    "    <li> 3 - Tweet Relevante </li>\n",
    "    <li> 4 - Tweet Muito Relevante </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the classifier\n",
    "classifier = NaiveBayesClassificator(n_gram=2, alpha=8, class_prob='equal', stem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading our training data\n",
    "df_train = pd.read_excel('smartfit_naivebayes_5categorias.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the training data to the classifier\n",
    "classifier.fit(df_train, \"Treinamento\", \"Classificação\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading our test data\n",
    "df_test = pd.read_excel('smartfit_naivebayes_5categorias.xlsx', sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the categories for our test data\n",
    "pred = classifier.predict(df_test[\"Teste\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador: 114 acertos -> 57.00% de acerto\n"
     ]
    }
   ],
   "source": [
    "# Evaluating our predictions\n",
    "acc = classifier.evaluate(df_test[\"Classificação\"], pred)\n",
    "\n",
    "print(\"Classificador: {} acertos -> {:.2f}% de acerto\".format(acc[1], 100*acc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Assim como fizemos com o classificador para 3 categorias, iremos criar uma matrix de confusão para nosso classificador.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   4,   1,   0],\n",
       "       [  0,   1,  21,   1,   0],\n",
       "       [  0,   0, 109,   3,   0],\n",
       "       [  0,   0,  50,   4,   0],\n",
       "       [  0,   0,   4,   2,   0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.confusion_matrix(df_test[\"Classificação\"], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Novamente buscaremos entender as classificações com base em uma tabela mais simples</p>\n",
    "\n",
    "| ---------            | Muito Irrelevante      | Irrelevante    | Neutro     |Relevante  |Muito Relevante|\n",
    "| ---------            | -------------          |----------------| ---------- |---------- |----------     |\n",
    "|**Muito Irrelevante** | 0                      | 0              | 4          |1          |0              |\n",
    "|**Irrelevante**       | 0                      | 1              | 21         |1          |0              |\n",
    "|**Neutro**            | 0                      | 0              | 109        |3          |0              |\n",
    "|**Relevante**         | 0                      | 0              | 50         |4          |0              |\n",
    "|**Muito Relevante**   | 0                      | 0              | 4          |2          |0              |\n",
    "\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase muito irrelevante}) = \\frac{0}{5} = 0\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase irrelevante}) = \\frac{1}{23} = 0.043\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase neutra}) = \\frac{109}{112} = 0.973\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase relevante}) = \\frac{4}{54} = 0.074\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase muito relevante}) = \\frac{0}{6} = 0\n",
    "$\n",
    "\n",
    "<p>Como podemos ver, quando damos um dataset com mais características, o classificador acaba não desempenhando um papel tão bom. Apesar de o grupo considerar 57% de acerto um valor razoável para 5 características (já que quando em um chute suas chances de acerto seriam de 20%), quando observamos as probabilidades de acerto para características específicas, o desempenho não é tão bom.</p>\n",
    "<p>Porém, o nosso pensamento é de que as diferenças nas quantidades de certas classificações pode ter prejudicado o nosso classificador. Vejamos a distribuição das classificações:\n",
    "    <ul>\n",
    "        <li>Muito Irrelevantes: 2.5%</li>\n",
    "        <li>Irrelevantes: 11.5%</li>\n",
    "        <li>Neutros: 56%</li>\n",
    "        <li>Relevantes: 27%</li>\n",
    "        <li>Muito Relevantes: 3%</li>\n",
    "    </ul>\n",
    "    \n",
    "Analisando-as, podemos perceber que a quantidade de frases (e com isso, de palavras) é menor para os extremos. Com isso, acreditamos que seja mais dificil para o classificador obter uma classificação razoavelmente boa.</p>\n",
    "\n",
    "<p>Para entender se é um problema do nosso modelo, ou se nossa ideia de que a distribuição das categorias impacta a classificação, pensamos que seria viavel utilizar a classe MultinomialNB do módulo Scikit.learn e vizualiar a matriz de confusão resultante da classificação dessa classe.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  1,  3,  0],\n",
       "       [ 0,  1, 16,  6,  0],\n",
       "       [ 0,  0, 91, 21,  0],\n",
       "       [ 0,  0, 41, 13,  0],\n",
       "       [ 0,  1,  3,  2,  0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stop_words_list = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=stop_words_list)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf = text_clf.fit(df_train.Treinamento, df_train.Classificação)\n",
    "predicted = text_clf.predict(df_test.Teste)\n",
    "\n",
    "classifier.confusion_matrix(df_test.Classificação, pd.Series(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Agora criaremos a tabela para a matriz de confusão do MultinomialNB</p>\n",
    "\n",
    "| ---------            | Muito Irrelevante      | Irrelevante    | Neutro     |Relevante  |Muito Relevante|\n",
    "| ---------            | -------------          |----------------| ---------- |---------- |----------     |\n",
    "|**Muito Irrelevante** | 0                      | 1              | 1          |3          |0              |\n",
    "|**Irrelevante**       | 0                      | 1              | 16         |6          |0              |\n",
    "|**Neutro**            | 0                      | 0              | 91         |21         |0              |\n",
    "|**Relevante**         | 0                      | 0              | 41         |13         |0              |\n",
    "|**Muito Relevante**   | 0                      | 1              | 3          |2          |0              |\n",
    "\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase muito irrelevante}) = \\frac{0}{5} = 0\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase irrelevante}) = \\frac{1}{23} = 0.043\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase neutras}) = \\frac{91}{112} = 0.812\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase relevante}) = \\frac{13}{54} = 0.241\n",
    "$\n",
    "<p></p>\n",
    "$\n",
    "\\mathcal{P} (\\text{acertar | frase muito relevante}) = \\frac{0}{6} = 0\n",
    "$\n",
    "\n",
    "<p>Como podemos ver, até mesmo um módulo já existente do python (criado por desenvolvedores com conhecimento do assunto) acaba se confundindo com a base de dados. Nosso classificador acaba tendo até um desempenho melhor em classificar frases neutras (porém, acaba desempenhando um pouco pior na classificação de frases relevantes.</p>\n",
    "<p>Com esses dados em mãos, nós concluimos que nosso classificador possui um desempenho razoável nessa base de dados em questão.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "<p>Testando testar o classificador em duas situações diferentes (trabalhando com 3 ou 5 características possíveis) obtivemos resultados diferentes para as situações. Na primeira (3 possibilidades), o classificador obteve um reultado interessante, tanto em termos globais (porcentagem de acerto geral), como em específicos (porcentagem de acerto dentro de uma determinada característica).</p>\n",
    "<p>Já na segunda situação (5 possibilidades), o classificador obteve um bom desempenho somente na classificação global. Quando analizadas as classificações específicas, ele obteve um bom desempenho somente para uma categoria. Em nossa opinião isso se deve ao fato de na base de dados (e na base de testes), as classificações estarem muito concentradas em uma única possibilidade, o que impactaria o funcionamento do classificador.</p>\n",
    "<p></p>\n",
    "<h5>Possívei Melhorias</h5>\n",
    "<p>Estruturando possíveis melhorias para o futuro (pois todo desenvolvedor gostaria de ver seu projeto ser continuado!), o grupo elencou algumas possibilidades:\n",
    "    <ul>\n",
    "        <li>Implementação de algoritmo de TF-IDF (<i>term frequency–inverse document frequency</i>)</li>\n",
    "        <li>Implementação de algoritmo que automatiza a escolha do Alpha (pois atualmente nós precisamos rodar um loop manualmente para descobrir o melhor valor de alpha</li>\n",
    "        <li>Melhora da classe para aceitar sentenças em inglês e possibilitar a <i>stemização</i> e retirada de stop-words da língua</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Perguntas Gerais</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Por que não usar o classificador para obter mais amostras de treinamento?</h4>\n",
    "\n",
    "<p>Classificando manualmente as amostras de treinamento, criamos um referencial para nosso classificador, “ensinando-o” o que considerar irrelevante, bom ou ruim. Em outras palavras criamos um data frame em que o classificador possa se embasar ao classificar novas amostras. </p>\n",
    "\n",
    "<p>Uma vez que as amostras de treinamento têm essa utilidade, seria imprudente utilizar o próprio classificador para gerar mais amostras para ele próprio treinar. O usuário não teria como saber se a classificação feita pelo programa é correta, pois o programa por si só não é capaz de distinguir as classes positivas, negativas e irrelevantes  sem embasamento em amostras classificadas pelo o usuário</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Diferente cenário onde pode ser ultilizado Naïve Bayes</h4>\n",
    "\n",
    "* Desenvolvimento de um programa para detecção de falhas de um manipulador robótico:\n",
    "\n",
    "   <p> Alguns manipuladores robóticos podem apresentar problemas de calibração e em muitos casos são desenvolvidos programas para identificar essas falhas. O classificador de Naive Bayes pode ser útil para distinguir a precisão desse programa e se realmente identificou um erro \"relevante\". Uma demonstração formal dessa ultilização pode ser encontrada no link abaixo </p>\n",
    "\n",
    "    <p>http://abcm.org.br/upload/files/PII_I_03%281%29.pdf</p>\n",
    "\n",
    "    <p>É possível observar nesse ensaio que foi classficado cada tipo de erro que o programa detecta. Assim foram feitos testes para cada classe de erros e ,a partir da observação dos testes, calcular a precisão do programa. Com isso, é possível usar a lógica do classificador de Naive Bayes para ter a probabilidade da  identificação de erros que o programa detecta (neste caso, o programa tem 83% de acerto na identificação de erros).</p> \n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
