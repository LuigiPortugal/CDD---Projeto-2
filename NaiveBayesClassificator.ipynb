{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassificator:\n",
    "    \n",
    "    def __init__(self, n_gram=1, stem=True, stop_words=True, alpha=1, class_prob=None):\n",
    "        self.n_gram = n_gram\n",
    "        self.stem = stem\n",
    "        self.stop_words = stop_words\n",
    "        self.alpha = alpha\n",
    "        self.class_prob = class_prob\n",
    "        self.stemmer = nltk.stem.RSLPStemmer()\n",
    "        self.stop_words_list = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    def _clean_sentence(self, sentence):\n",
    "        \n",
    "        string = str(sentence)\n",
    "    \n",
    "        # Cleaning unwanted characters on the sentence\n",
    "        string = string.replace(\":\", \" \")\n",
    "        string = string.replace(\";\", \" \")\n",
    "        string = string.replace(\",\", \" \")\n",
    "        string = string.replace(\"?\", \" \")\n",
    "        string = string.replace(\"(\", \" \")\n",
    "        string = string.replace(\")\", \" \")\n",
    "        string = string.replace(\"\\n\", \" \")\n",
    "        string = string.replace(\"'\", \" \")\n",
    "        string = string.replace(\".\", \" \")\n",
    "        string = string.replace('\"', \" \")\n",
    "        string = string.replace(\"!\", \" \")\n",
    "        string = string.replace(\"@\", \" \")\n",
    "        string = string.lower()\n",
    "\n",
    "        # Converting the sentence into a list of words\n",
    "        string_list = []\n",
    "        \n",
    "        for word in string.split():\n",
    "            if self.stop_words:\n",
    "                if word not in self.stop_words_list:\n",
    "                    if self.stem:\n",
    "                        string_list.append(self.stemmer.stem(word))\n",
    "                    else:\n",
    "                        string_list.append(word)\n",
    "            else:\n",
    "                if self.stem:\n",
    "                    string_list.append(self.stemmer.stem(word))\n",
    "                else:\n",
    "                    string_list.append(word)\n",
    "                    \n",
    "        \n",
    "                \n",
    "        return self._create_gram(string_list)\n",
    "\n",
    "    def _create_gram(self, words_list):\n",
    "        bigram = []\n",
    "        for n in range(len(words_list) + 1 - self.n_gram):\n",
    "            bigram.append(\" \".join(words_list[n:n+self.n_gram]))\n",
    "        return bigram\n",
    "\n",
    "    def _create_dict(self, sentences_series):\n",
    "\n",
    "        self.count = {}\n",
    "\n",
    "        for sentence in sentences_series:\n",
    "            words_list = self._clean_sentence(sentence)\n",
    "            for word in words_list:\n",
    "                if word in self.count:\n",
    "                    self.count[word] += 1\n",
    "                else:\n",
    "                    self.count[word] = 1\n",
    "                        \n",
    "        return self.count\n",
    "    \n",
    "    def _get_d(self, df, x_label):\n",
    "        \n",
    "        words = []\n",
    "        for sentence in df[x_label]:\n",
    "            for word in self._clean_sentence(sentence):\n",
    "                if word not in words:\n",
    "                    words.append(word)\n",
    "                    \n",
    "        return len(words)\n",
    "    \n",
    "    def _calc_prob(self, sentence, e):\n",
    "        \n",
    "        prob = log(self.classes_dicts[e][\"class_prob\"])\n",
    "    \n",
    "        # Alpha factor for the LaPlace smoothing\n",
    "        total = self.classes_dicts[e][\"n_words\"] + self.alpha*self.d\n",
    "        \n",
    "        for word in self._clean_sentence(sentence):\n",
    "            if word in self.classes_dicts[e][\"words\"]:\n",
    "                count = self.classes_dicts[e][\"words\"][word] + self.alpha\n",
    "            else:\n",
    "                count = self.alpha\n",
    "            prob += log(count/total)\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def _classify(self, sentence):\n",
    "        \n",
    "        highest = [None, None]\n",
    "        \n",
    "        for e in self.classes:\n",
    "            classes_probs = self._calc_prob(sentence, e)\n",
    "            if highest[0] is not None:\n",
    "                if classes_probs > highest[1]:\n",
    "                    highest[0] = e\n",
    "                    highest[1] = classes_probs\n",
    "            else:\n",
    "                highest[0] = e\n",
    "                highest[1] = classes_probs\n",
    "                \n",
    "        return highest[0]            \n",
    "    \n",
    "    def fit(self, df, x_label, y_label):\n",
    "        \n",
    "        self.df = df\n",
    "        self.x_label = x_label\n",
    "        self.y_label = y_label\n",
    "        \n",
    "        self.classes = []\n",
    "        for e in df[y_label]:\n",
    "            if e not in self.classes:\n",
    "                self.classes.append(e)\n",
    "                \n",
    "        self.classes_dicts = {}\n",
    "        \n",
    "        for e in self.classes:\n",
    "            self.classes_dicts[e] = {}\n",
    "            self.classes_dicts[e][\"words\"] = self._create_dict(df[df[y_label] == e][x_label])\n",
    "            self.classes_dicts[e][\"n_words\"] = len(self.classes_dicts[e][\"words\"])\n",
    "            if self.class_prob == None:\n",
    "                self.classes_dicts[e][\"class_prob\"] = df[df[y_label] == e][x_label].count()/df[x_label].count()\n",
    "            elif self.class_prob == \"equal\":\n",
    "                self.classes_dicts[e][\"class_prob\"] = 1/len(self.classes)\n",
    "            \n",
    "        self.d = self._get_d(df, x_label)\n",
    "            \n",
    "    def predict(self, sentence_series):\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for sentence in sentence_series:\n",
    "            predictions.append(self._classify(sentence))\n",
    "            \n",
    "        return pd.Series(predictions)\n",
    "    \n",
    "    def evaluate(self, y_test, y_pred):\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for e in range(len(y_test)):\n",
    "            if y_test.loc[e] == y_pred.loc[e]:\n",
    "                count += 1\n",
    "                \n",
    "        performance = count/(y_test.count())\n",
    "        return (performance, count)\n",
    "    \n",
    "    def confusion_matrix(self, y_test, y_pred):\n",
    "        \n",
    "        n = [[0] * len(self.classes)] * len(self.classes)\n",
    "        cm = np.array(n)\n",
    "        \n",
    "        for e in range(len(y_test)):\n",
    "            cls = y_test.loc[e]\n",
    "            pred = y_pred.loc[e]\n",
    "            cm[cls][pred] += 1\n",
    "            \n",
    "        return cm\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
